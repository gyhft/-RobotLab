#### RM比赛
##### 哨兵
##### 1.规则
①取消哨兵开局的无敌状态，开局时哨兵即为满级状态；

②取消哨兵阵亡与基地护甲展开状态之间的关联；

③取消哨兵的巡逻区，全场活动空间不受限制；

④ 哨兵的初始发单量为300发，比赛开始后，每隔 1 分钟，哨兵机器人可以通过领己方补给区增益点获取 100 发允许发弹量，未通过此方式获取的允许发弹量可以累积，并且可以补给区获取或者远程兑换发单量；

⑤ 哨兵底盘能量使用超过20000J后，将进入虚弱状态，底盘功率限制将降至原来的三分之一；

(ex.1)地形跨越增益和增益点机制；

(ex.2)新增堡垒机制，哨兵激活堡垒增益后拥有额外发单量和更高热量限制。
##### 任务的相关行为如下：

① 巡逻：哨兵机器人需要恰当移动并扫描到试图入侵己方势力范围的敌方机器人；

② 攻击：哨兵机器人需要进攻并击败敌方机器人；

③ 占领：哨兵机器人需要占领增益点（尤其堡垒增益点）以增强己方团队实力，并在此基础上防御敌方机器人。
##### 针对巡逻任务：
总的来说是自动瞄准，精确识别敌方移动机器人的装甲板，稳定跟随。可以对装甲板灯条进行二值化和条件匹配，则认为装甲板，通过卡尔曼滤波进行装甲板运动预测，实现快速跟随。

针对装甲板贴纸的识别

分为两种方案，1个是传统方案，用Opencv;2是深度学习方案，用yolo模型

* 传统方案介绍：

a.图像预处理：把彩色图像转化为灰度图，如opencv中的cv2.cvtColor()函数实现；降噪：可采用高斯滤波、中值滤波等

b.装甲板特征提取：颜色特征，用hsv颜色空间，设定颜色区域。如，敌方装甲板为红色，就在cv2.inRange函数筛选出红色区域。形状特征：经过边缘检测（如Canny边缘检测）提取轮廓，再根据轮廓的周长、面积、长宽比等几何属性筛选，剔除不符合装甲板形状特征的轮廓，Opencv的cv2.findContours函数可辅助找到图像中的轮廓。

c.目标识别与筛选：模板匹配，准备好不同角度、距离下敌方装甲板的标准模板图像，用模板匹配算法（如TM_CCOEFF_NORMED方法）与预处理后的实时图像对比，匹配度高的区域大概率是装甲板所在。还可以提取装甲板的HOG/LBP等特征，用支持向量机SVM、Adaboost等分类器训练模型，实现装甲板识别。

* 深度学习方案：Yolo模型（大数据视觉任务）

a.数据收集与标注

首先是做数据集的增强。

处理方法可以参考[智能汽车视觉组的图像数据集处理](https://blog.csdn.net/weixin_52126342/article/details/126170935?ops_request_misc=&request_id=&biz_id=102&utm_term=%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6%E8%A7%86%E8%A7%89%E7%BB%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A2%9E%E5%BC%BA&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-126170935.142^v101^pc_search_result_base9&spm=1018.2226.3001.4187)，主要方法为裁剪，旋转，模糊，加噪声，数据集大概做到1w张左右，主要是为了后面部署yolo v8模型或者v11模型，提高模型的泛化能力。

在比赛场景中，采集大量包含敌方装甲板的图像数据，这些数据应涵盖不同的角度、距离、光照条件以及装甲板的各种状态。

标注数据：使用如LabelImg等，对收集的数据进行标注，标注出装甲板的位置和类别，为模型训练提供准确的监督信息。

b.模型训练
采用的是英伟达jetson ornx 8G的开发板，安装pytorch等深度学习框架以及yolov8的相关依赖库。调整yolov8的训练参数，如学习率、批次大小、训练轮数等。
模型训练：将标注那好的数据输入到yolov8模型中进行训练。在训练过程中，监控模型的损失函数值和评估指标，如准确率、召回率、平均精度均值，根据这些指标调整训练参数和优化模型结构。


2.相机和英伟达开发板（电控任务）

使用的zed2i的深度相机，已经做好了相机的内外参的标定，可以写入矩阵数据就可以使用。相机通过usb连接到英伟达jetson ornx 8G芯片，拍到的图片传到yolo模型进行识别，识别成功后通过串口发送到下位机stm32,做自瞄跟随。
